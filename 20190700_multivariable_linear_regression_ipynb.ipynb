{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multivariable linear regression. ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CohImoFgnvvB"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viridis45/Python-data-analysis/blob/master/multivariable_linear_regression_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CohImoFgnvvB",
        "colab_type": "text"
      },
      "source": [
        "# Understanding the basic structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDmgc8bNSgCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "x1d = [70,90, 88,95,75]\n",
        "x2d = [80,88,90,98,65]\n",
        "x3d = [75,93,90,100,70]\n",
        "yd = [150, 185, 180, 200, 140]\n",
        "\n",
        "x1 = tf.placeholder(tf.float32)\n",
        "x2 = tf.placeholder(tf.float32)\n",
        "x3 = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
        "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
        "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hf = x1*w1 + x2*w2 + x3*w3 + b\n",
        "cost = tf.reduce_mean(tf.square(hf-y))\n",
        "train = tf.train.GradientDescentOptimizer(1e-5).minimize(cost)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x1:x1d, x2:x2d, x3:x3d, y:yd})\n",
        "  if step % 10 == 0:\n",
        "    print(step, 'cost:', cv, 'prediction:', hv)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlyJ4tQeeJXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrK9Qy4_eJUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeLWiBbOn4ix",
        "colab_type": "text"
      },
      "source": [
        "## collected laout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad-JKEvVTyMT",
        "colab_type": "code",
        "outputId": "d0ba0c15-4360-4661-844b-336e3433b67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "# same thing but for collected layout\n",
        "\n",
        "\n",
        "x1d = [ [70,90, 88,95,75],[80,88,90,98,65],[75,93,90,100,70] ]\n",
        "x1d = np.transpose(x1d)\n",
        "yd = np.transpose([150, 185, 180, 200, 140])\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape = [None, 3]) #not 5,3\n",
        "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "w = tf.Variable(tf.random_normal([3,1]), name='weight1')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "#hf = x1*w1 + x2*w2 + x3*w3 + b #cannot be used due to elementwise product. need dot product\n",
        "hf = tf.matmul(x,w)+b\n",
        "cost = tf.reduce_mean(tf.square(hf-y))\n",
        "train = tf.train.GradientDescentOptimizer(1e-5).minimize(cost)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:x1d, y:yd})\n",
        "  if step % 10 == 0:\n",
        "    print(step, 'cost:', cv, 'prediction:', hv)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a9b268b63193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0myd\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cost:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prediction:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1149\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1150\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (5,) for Tensor 'Placeholder_25:0', which has shape '(?, 1)'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpKvo_Fin-ci",
        "colab_type": "text"
      },
      "source": [
        "## another one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZzrbTswfi4A",
        "colab_type": "code",
        "outputId": "df252a02-0e04-4f4f-b593-2c4ff158c3bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vJG0e6SbMsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "xy = np.loadtxt('/content/drive/My Drive/T4IR/colab/0730data/test-score.csv',\n",
        "               delimiter = ',', dtype = np.float32)\n",
        "xtrain = xy[:,0:3]\n",
        "ytrain = np.vstack(xy[:,3])\n",
        "\n",
        "\n",
        "xdata = tf.placeholder(tf.float32, shape = [None, 3])\n",
        "ydata = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "w = tf.Variable(tf.random_normal([3,1]), name='weight1')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hf = tf.matmul(x,w)+b\n",
        "cost = tf.reduce_mean(tf.square(hf-y))\n",
        "train = tf.train.GradientDescentOptimizer(1e-5).minimize(cost)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)\n",
        "\n",
        "\n",
        "\n",
        "for step in range(2001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:xtrain, y:ytrain})\n",
        "  if step == 2000:\n",
        "    print(step, 'cost:', cv, 'prediction:', hv)\n",
        "\n",
        "\n",
        "print(\"========================================\")\n",
        "    \n",
        "q = [[100,70,102],[60,70,100],[80, 90, 95]]\n",
        "q = np.transpose(q)\n",
        "for i in q:\n",
        "  print(sess.run(hf, feed_dict={x:i.reshape(-1,3)}))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kES5rq9ef3q8",
        "colab_type": "code",
        "outputId": "fb908011-9703-4538-ce75-b03f23757594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAJiEIqUoN41",
        "colab_type": "text"
      },
      "source": [
        "## Practice with stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWKo3he_ihRa",
        "colab_type": "code",
        "outputId": "14d9c99e-88f5-47aa-831b-43b691820f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "import pandas as pd\n",
        "tsla = pd.read_csv('/content/drive/My Drive/T4IR/colab/0730data/TSLA.csv', parse_dates = ['Date'])\n",
        "\n",
        "train_data = tsla[['Open', 'High', 'Low']].iloc[:-10,:]\n",
        "train_label = tsla[['Close']].iloc[:-10,:]\n",
        "test_data = tsla[['Open', 'High', 'Low']].iloc[-10:,:]\n",
        "test_label =tsla[['Close']].iloc[-10:,:]\n",
        "\n",
        "\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)\n",
        "\n",
        "tdata = tf.placeholder(tf.float32, shape = [None, 3])\n",
        "tlabel = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "w = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hf = tf.matmul(x,w)+b\n",
        "cost = tf.reduce_mean(tf.square(hf-y))\n",
        "train = tf.train.GradientDescentOptimizer(1e-7).minimize(cost) #diverged --> lowered the leraning rate meh\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for step in range(2001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:train_data, y:train_label})\n",
        "#  if step == 2000:\n",
        "#     print(step, 'cost:', cv, 'prediction:', hv)\n",
        "    \n",
        "    \n",
        "print (\"==============difference from the real value==================\")\n",
        "print(test_label - sess.run(hf, feed_dict={x:test_data}))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"===============volume prediction=====================\")\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)\n",
        "\n",
        "\n",
        "train_data = tsla[['Open']]\n",
        "train_label = tsla[['Close']]\n",
        "\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)\n",
        "\n",
        "tdata = tf.placeholder(tf.float32, shape = [None, 1])\n",
        "tlabel = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "w2 = tf.Variable(tf.random_normal([1,1]), name='weight')\n",
        "b2 = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "y2 = tf.placeholder(tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "hf = x2*w2 + b2\n",
        "cost = tf.reduce_mean(tf.square(hf-y2))\n",
        "train = tf.train.GradientDescentOptimizer(1e-7).minimize(cost)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x2:train_data, y2:train_label})\n",
        "\n",
        "\n",
        "  \n",
        "print('predicted volume:',sess.run(hf, feed_dict={x2:227.09}))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============difference from the real value==================\n",
            "         Close\n",
            "241   8.923691\n",
            "242   3.475190\n",
            "243   1.135666\n",
            "244   9.005173\n",
            "245  -2.153289\n",
            "246   8.115676\n",
            "247  12.806152\n",
            "248 -10.256653\n",
            "249   0.917953\n",
            "250  15.038650\n",
            "===============volume prediction=====================\n",
            "predicted volume: [[227.09866]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERIu-qBHnnWM",
        "colab_type": "text"
      },
      "source": [
        "# practice with housing price\n",
        "\n",
        "1. sqt_living 에 따른 가격\n",
        "- 데이터 8:2 분리\n",
        "2. sqft_living, bedrooms, bathrooms 에 따른 price\n",
        "3. sqft_living, bedrooms, bathrooms, sqft_lot, floor2 zipcode 에 따른 price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AehYlg6_nnHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "root = '/content/drive/My Drive/T4IR/colab/0730data/hosing_kaggle'\n",
        "data1 = pd.read_csv(root+'/train.csv', usecols=['bedrooms', 'bathrooms', 'sqft_living'])\n",
        "data2 = pd.read_csv(root+'/train.csv', usecols=['bedrooms', 'bathrooms', 'sqft_living','sqft_lot', 'floors', 'zipcode'])\n",
        "label = pd.read_csv(root+'/train.csv', usecols=['price'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sicm1ero1UJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_label, test_label = train_test_split(data1, label, test_size=0.2, random_state=42)\n",
        "train_data2, test_data2, train_label2, test_label2 = train_test_split(data2, label, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQN9t7l6sBkk",
        "colab_type": "code",
        "outputId": "e5d74abf-6f11-46e6-9782-64f434fd482d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(train_data.shape, test_data.shape, train_label.shape, test_label.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12028, 3) (3007, 3) (12028, 1) (3007, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiS2vO7qrMHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# init = tf.initialize_all_variables()\n",
        "# sess.run(init)\n",
        "\n",
        "tdata = tf.placeholder(tf.float32, shape = [None, 3])\n",
        "tlabel = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "w = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hf = tf.matmul(x,w)+b\n",
        "cost = tf.reduce_mean(tf.square(hf-y))\n",
        "train = tf.train.GradientDescentOptimizer(1e-7).minimize(cost)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for step in range(2001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:train_data, y:train_label})\n",
        "#   if step == 2000:\n",
        "#     print(step, 'cost:', cv, 'prediction:', hv)\n",
        "    \n",
        "    \n",
        "print (\"==============difference from the real value==================\")\n",
        "print(test_label - sess.run(hf, feed_dict={x:test_data}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B3_zzaNuFmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)\n",
        "\n",
        "tdata = tf.placeholder(tf.float32, shape = [None, 6])\n",
        "tlabel = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "w = tf.Variable(tf.random_normal([6,1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hf = tf.matmul(x,w)+b\n",
        "cost = tf.reduce_mean(tf.square(hf-y))\n",
        "train = tf.train.GradientDescentOptimizer(1e-10).minimize(cost)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for step in range(3001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:train_data2, y:train_label2})\n",
        "#   if step == 3000:\n",
        "#     print(step, 'cost:', cv, 'prediction:', hv)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "print (\"==============difference from the real value==================\")\n",
        "print(test_label2 - sess.run(hf, feed_dict={x:test_data2}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aovy0qL_0ODf",
        "colab_type": "code",
        "outputId": "86cf3731-7a36-402d-9ae4-f845af499079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "##############\n",
        "##############\n",
        "##############\n",
        "for step in range(3001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:train_data2, y:train_label2})\n",
        "  if step == 3000:\n",
        "      wv,bv,lv,_ = sess.run([cost, w, b, train], feed_dict={x:test_data2, y:test_label2})\n",
        "      print(\"w:%s b:%s cost:%s\" % (wv, bv, lv))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:68811420000.0 b:[[-1.2588859e+00]\n",
            " [ 8.5329622e-01]\n",
            " [ 2.2278195e+02]\n",
            " [ 2.3646345e-02]\n",
            " [-1.9491901e-01]\n",
            " [ 8.1520897e-01]] cost:[0.4146298]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nEtuU-RuSzy",
        "colab_type": "code",
        "outputId": "816f5422-47fb-45a2-9fd5-23a22a72a4f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "data2_scaled = preprocessing.scale(data2)\n",
        "label_scaled = preprocessing.scale(label)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(data2_scaled)\n",
        "plt.axis([-5, 10, 0, 15000])\n",
        "# i think it's maybe okay"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-5, 10, 0, 15000]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/weJpt3h9fAUzwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5IItGWjv4Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data2_2, test_data2_2, train_label2_2, test_label2_2 = train_test_split(data2_scaled, label_scaled, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esXUmwOzv7XW",
        "colab_type": "code",
        "outputId": "36d56275-a1d8-4617-f8c0-1267bf86c199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)\n",
        "\n",
        "tdata = tf.placeholder(tf.float32, shape = [None, 6])\n",
        "tlabel = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "w = tf.Variable(tf.random_normal([6,1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hf = tf.matmul(x,w)+b\n",
        "cost = tf.reduce_mean(tf.square(hf-y))\n",
        "train = tf.train.GradientDescentOptimizer(1e-5).minimize(cost)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for step in range(3001):\n",
        "  cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:train_data2_2, y:train_label2_2})\n",
        "#   if step == 3000:\n",
        "#     print(step, 'cost:', cv, 'prediction:', hv)\n",
        "\n",
        "\n",
        "    \n",
        "print (\"==============difference from the real value==================\")\n",
        "print(test_label2_2 - sess.run(hf, feed_dict={x:test_data2_2}))\n",
        "# I used scale!\n",
        "# it's not very effective..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============difference from the real value==================\n",
            "[[-0.2192659 ]\n",
            " [-3.53402486]\n",
            " [-1.60742124]\n",
            " ...\n",
            " [-2.41806873]\n",
            " [-1.51358731]\n",
            " [-3.19507753]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anlmsoFc2Cg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}